{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using Bing Liu lexicon\n",
    "### By Mohammed KASRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis aims to determine whether a given text contains negative, positive, or neutral emotions. It’s a form of text analytics that uses natural language processing (NLP) and machine learning. Sentiment analysis is also known as “opinion mining” or “emotion artificial intelligence”.\n",
    "\n",
    "There are two common approches for sentiment analysis:\n",
    "<ul>\n",
    "    <li>Machine Learning</li>\n",
    "    <li>Rule-Based</li>\n",
    "</ul>\n",
    "\n",
    "A rule-based approach usually uses a lexicon, also known as a dictionary or vocabulary. In sentiment analysis, a sentiment lexicon is a list of words\n",
    "with thier corresponding sentiment polarity (magnitude of negative or positive score), parts of speech (POS) tags, emotion and so on.\n",
    "\n",
    "### The most popular sentiment lexicon are as follow:\n",
    "\n",
    "- Bing Liu’s lexicon\n",
    "- MPQA subjectivity lexicon\n",
    "- TextBlob lexicon\n",
    "- AFINN lexicon\n",
    "- SentiWordNet lexicon\n",
    "- VADER lexicon\n",
    "\n",
    "In this jupyter notebook we will focus on how to perform sentiment analyis using Bing Liu lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Bing Liu lexicon ?\n",
    "\n",
    "Bing Liu lexicon (Opinion Lexicon) is a list of English positive and negative opinion words or sentiment words. This lexicon was built to predict the polarity of product features phrases that are summarized to provide an overall score for that product feature. The list contains 2006 positive words and 4783 negative words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use Bing Liu lexicon ?\n",
    "The goal of this part is to provide you with all the prerequisites such as the dependencies, the dataset, and the actual implementation to conduct sentiment analysis using Opinion Lexicon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import text_normalizer as tn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_normalizer in this case is a simple python script that contains all the necessary functions to preprocess the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>we never really feel involved with the story ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>this is one of polanski 's best films .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0     no movement , no yuks , not much of anything .\n",
       "1          0  a gob of drivel so sickly sweet , even the eag...\n",
       "2          0  gangs of new york is an unapologetic mess , wh...\n",
       "3          0  we never really feel involved with the story ,...\n",
       "4          1            this is one of polanski 's best films ."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/test.tsv', sep='\\t', header=None)\n",
    "data.columns=['sentiment','text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.text.tolist()\n",
    "sentiments = ['positive' if label==1 else 'negative' for label in data.sentiment.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preporocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmax/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = tn.normalize_corpus(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis with Bing Liu lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "liu = pd.read_csv('./lexicons/BingLiu.csv')\n",
    "liu.columns =['word','sentiment']\n",
    "liu_lexicon={}\n",
    "for index, row in liu.iterrows():\n",
    "    if row['sentiment']=='positive':\n",
    "        liu_lexicon[row['word']] = 1\n",
    "    else:\n",
    "        liu_lexicon[row['word']] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The rule-based method to classify sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sa_bingliu_sum(text,lexicon):\n",
    "    score = 0\n",
    "    for word in text.split():\n",
    "        if word in lexicon:\n",
    "            score += int(lexicon[word])\n",
    "\n",
    "    if (score > 0):\n",
    "        return 'positive'\n",
    "    return 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: this is one of polanski 's best films .\n",
      "Sentiment: positive\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "review = sentences[4]\n",
    "print('Review:', review)\n",
    "print('Sentiment:', sentiments[4])\n",
    "print('Predicted sentiment:', sa_bingliu_sum(review,liu_lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiments = [sa_bingliu_sum(review,liu_lexicon) for review in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  71.17% \n",
      "Precision: 71.56% \n",
      "Recall:    71.17% \n",
      "F1 Score:  71.03% \n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(sentiments,predicted_sentiments)\n",
    "precision = precision_score(sentiments,predicted_sentiments, average='weighted')\n",
    "recall = recall_score(sentiments,predicted_sentiments, average='weighted')\n",
    "f1 = f1_score(sentiments,predicted_sentiments, average='weighted')\n",
    "print('Accuracy:  {:2.2%} '.format(accuracy))\n",
    "print('Precision: {:2.2%} '.format(precision))\n",
    "print('Recall:    {:2.2%} '.format(recall))\n",
    "print('F1 Score:  {:2.2%} '.format(f1)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c2bcda995b8bc375aa0f3dd8cad4b79e8618d7f039f200079a1433a5d095f54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
